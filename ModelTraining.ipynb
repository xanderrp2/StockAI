{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxIi8VmsYgP6YXb6+kjqFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xanderrp2/StockAI/blob/main/ModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/drive/My Drive/stockNews.csv')\n",
        "\n",
        "# Extract features and target\n",
        "headlines = [eval(x) for x in data['headlines']]  # Convert stringified lists to actual lists\n",
        "contents = [eval(x) for x in data['contents']]\n",
        "percent_changes = data['percent_change'].values\n",
        "ema = data['EMA'].values\n",
        "macd = np.array([eval(x) for x in data['MACD']])  # Convert stringified tuples to array\n",
        "\n",
        "# Pad sequences for consistent input size\n",
        "X_headlines = pad_sequences(headlines, padding='post')\n",
        "X_contents = pad_sequences(contents, padding='post')\n",
        "X_ema = np.array(ema).reshape(-1, 1)\n",
        "X_macd = macd\n",
        "\n",
        "# Combine MACD into individual components\n",
        "X_macd_first = X_macd[:, 0].reshape(-1, 1)\n",
        "X_macd_second = X_macd[:, 1].reshape(-1, 1)\n",
        "\n",
        "# Target variable\n",
        "y = np.array(percent_changes)\n",
        "\n",
        "# Split into training and test sets\n",
        "(X_headlines_train, X_headlines_test,\n",
        " X_contents_train, X_contents_test,\n",
        " X_ema_train, X_ema_test,\n",
        " X_macd_first_train, X_macd_first_test,\n",
        " X_macd_second_train, X_macd_second_test,\n",
        " y_train, y_test) = train_test_split(\n",
        "    X_headlines, X_contents, X_ema, X_macd_first, X_macd_second, y,\n",
        "    test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model architecture\n",
        "# Input for headlines\n",
        "input_headlines = Input(shape=(X_headlines.shape[1],), name=\"headlines_input\")\n",
        "headlines_dense = Dense(64, activation=\"relu\")(input_headlines)\n",
        "\n",
        "# Input for contents\n",
        "input_contents = Input(shape=(X_contents.shape[1],), name=\"contents_input\")\n",
        "contents_dense = Dense(64, activation=\"relu\")(input_contents)\n",
        "\n",
        "# Input for EMA\n",
        "input_ema = Input(shape=(1,), name=\"ema_input\")\n",
        "ema_dense = Dense(16, activation=\"relu\")(input_ema)\n",
        "\n",
        "# Input for MACD components\n",
        "input_macd_first = Input(shape=(1,), name=\"macd_first_input\")\n",
        "macd_first_dense = Dense(16, activation=\"relu\")(input_macd_first)\n",
        "\n",
        "input_macd_second = Input(shape=(1,), name=\"macd_second_input\")\n",
        "macd_second_dense = Dense(16, activation=\"relu\")(input_macd_second)\n",
        "\n",
        "# Combine all inputs\n",
        "merged = Concatenate()([\n",
        "    headlines_dense, contents_dense, ema_dense, macd_first_dense, macd_second_dense\n",
        "])\n",
        "combined_dense = Dense(64, activation=\"relu\")(merged)\n",
        "out = Dense(1, activation=\"linear\", name=\"output_layer\")(combined_dense)\n",
        "\n",
        "# Define the model\n",
        "model = Model(\n",
        "    inputs=[input_headlines, input_contents, input_ema, input_macd_first, input_macd_second],\n",
        "    outputs=out\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_headlines_train, X_contents_train, X_ema_train, X_macd_first_train, X_macd_second_train],\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=8,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(\n",
        "    [X_headlines_test, X_contents_test, X_ema_test, X_macd_first_test, X_macd_second_test],\n",
        "    y_test,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bOFuqj6hPsUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770de2bd-c168-4d62-c3d5-20d31d6d4815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 8947.9395 - mae: 68.0841 - val_loss: 4311.5859 - val_mae: 58.6804\n",
            "Epoch 2/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 6669.2803 - mae: 58.4859 - val_loss: 3078.8088 - val_mae: 49.4973\n",
            "Epoch 3/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4753.5073 - mae: 49.0792 - val_loss: 2065.0547 - val_mae: 40.4207\n",
            "Epoch 4/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 3183.4019 - mae: 39.7950 - val_loss: 1265.6163 - val_mae: 31.4908\n",
            "Epoch 5/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 1947.5564 - mae: 30.6318 - val_loss: 673.9673 - val_mae: 22.7657\n",
            "Epoch 6/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 1036.6542 - mae: 21.6599 - val_loss: 280.1128 - val_mae: 14.3622\n",
            "Epoch 7/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 432.9324 - mae: 13.2491 - val_loss: 66.0698 - val_mae: 6.4254\n",
            "Epoch 8/8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 107.4302 - mae: 5.9894 - val_loss: 4.4475 - val_mae: 1.9342\n",
            "Test Loss: 7.989416599273682, Test MAE: 2.0316810607910156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_todays_percent_change(company_name, headlines, contents, ema, macd):\n",
        "    # Vectorize the input data (using the same logic as in training)\n",
        "    vectorized_headlines = [vectorize_text(headline, words) for headline in headlines]\n",
        "    vectorized_contents = [vectorize_text(content, words) for content in contents]\n",
        "\n",
        "    # Get the shape of X_headlines and X_contents from the training data\n",
        "    # Assuming you have access to these variables from your training script\n",
        "    global X_headlines, X_contents # Access the X_headlines and X_contents from the global scope\n",
        "\n",
        "    # Pad sequences\n",
        "    X_headlines_pred = pad_sequences([vectorized_headlines], padding='post', maxlen=X_headlines.shape[1])  # Ensure same length as training\n",
        "    X_contents_pred = pad_sequences([vectorized_contents], padding='post', maxlen=X_contents.shape[1])\n",
        "    X_ema = np.array([ema]).reshape(-1, 1)\n",
        "    X_macd = np.array(macd)  # Assuming macd is a tuple (MACD, Signal)\n",
        "    X_macd_first = X_macd[0].reshape(-1, 1)\n",
        "    X_macd_second = X_macd[1].reshape(-1, 1)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict([X_headlines_pred, X_contents_pred, X_ema, X_macd_first, X_macd_second])\n",
        "    return prediction[0][0]  # Return the predicted value"
      ],
      "metadata": {
        "id": "OaEYEkdCTemO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the predict_todays_percent_change function\n",
        "company_name = \"TSLA\"  # Replace with the desired company name\n",
        "today = datetime.now().strftime('%Y-%m-%d')\n",
        "# Fetch today's news for the company\n",
        "articles = fetch_news(query=\"Telsa\", day=today)\n",
        "\n",
        "# Organize and vectorize the news\n",
        "news_data = organize_news(articles)\n",
        "vectorizedNews = vectorizeNews(news_data)\n",
        "\n",
        "# Get the EMA and MACD values (you'll need to adjust this based on how you obtain them in your real-time environment)\n",
        "ema = getEMA(company_name)\n",
        "macd = MACD(company_name)\n",
        "\n",
        "# Prepare the input\n",
        "headlines = news_data['headlines']\n",
        "contents = news_data['contents']\n",
        "\n",
        "\n",
        "# Added check for None values\n",
        "predicted_change = predict_todays_percent_change(company_name, headlines, contents, ema, macd)\n",
        "print(f\"Predicted percentage change for {company_name}: {predicted_change}\")"
      ],
      "metadata": {
        "id": "_lOSoKhGVvtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}